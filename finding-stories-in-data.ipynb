{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Finding stories in data using Python and Jupyter notebooks\n",
    "[Journocoders London](https://www.meetup.com/Journocoders/), April 13, 2017  \n",
    "\n",
    "David Blood/[@davidcblood](https://twitter.com/davidcblood)/[first] dot [last] at ft.com\n",
    "\n",
    "## Introduction\n",
    "The [Jupyter](http://jupyter.org/) notebook provides an intuitive, flexible and shareable way to work with code. It's a potentially invaluable tool for journalists who need to analyse data quickly and reproducibly, particularly as part of a graphics-oriented workflow.\n",
    "\n",
    "This aim of this tutorial is to help you become familiar with the notebook and its role in a [Python](https://www.python.org/) data analysis toolkit. We'll start with a demographic dataset and explore and analyse it visually in the notebook to see what it can tell us about people who voted â€˜leaveâ€™ in the UK's EU referendum. To finish, we'll output a production-quality graphic using [Bokeh](http://bokeh.pydata.org/en/latest/).\n",
    "\n",
    "You'll need access to an empty Python 3 Jupyter notebook, ideally running on your local machine, although a cloud-based Jupyter environment is fine too.\n",
    "\n",
    "You're ready to start the tutorial when you're looking at this screen:\n",
    "\n",
    "![Empty Python 3 notebook](https://github.com/davidbjourno/finding-stories-in-data/raw/master/images/fsid-empty-notebook.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Bring your data into the notebook\n",
    "\n",
    "In Python-world, people often use the [pandas](http://pandas.pydata.org/) module for working with data. You don't have toâ€”there are other modules that do similar thingsâ€”but it's the most well-known and comprehensive (probably).\n",
    "\n",
    "Let's [import](https://docs.python.org/3/reference/import.html) pandas into our project and assign it to the variable `pd`, because that's easier to type than `pandas`. While we're at it, let's import all the other modules we'll need for this tutorial and also let [Matplotlib](http://matplotlib.org/) know that we want it to plot charts here in the notebook rather than in a separate window. Enter the following code into the first cell in your notebook and hit shift-return to run the code block:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import bokeh.plotting as bokeh\n",
    "from bokeh.io import output_notebook\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you encounter any error messages at this point, it's most likely because you don't have one or more of these modules installed on your system. Running\n",
    "```\n",
    "pip3 install pandas matplotlib numpy seaborn bokeh\n",
    "```\n",
    "from the command line should take care of that. If not, holler and I'll try to help you.\n",
    "\n",
    "As well as running your code, hitting shift-return in your first cell should have automatically created an empty cell below it. In that cell, we're going to use the `read_csv` method provided by pandas to, um, read our CSV.\n",
    "\n",
    "When pandas reads data from a CSV file, it automagically puts it into something called a _dataframe_. It's not important at this point to understand what a dataframe is or how it differs from other [Python data structures](https://docs.python.org/3/tutorial/datastructures.html?highlight=dictionary#data-structures). All you need to know for now is that it's an object containing structured data.\n",
    "\n",
    "We'll also assign our new dataframe to another variableâ€”`df`â€”so we can do things with it down the line.\n",
    "\n",
    "We do all of this in one go, like so (remember to hit shift-return):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/leave-demographics.csv') # Passing in the path to our local CSV file\n",
    "\n",
    "# If you're using an online notebook, pass in a URL instead of a local path:\n",
    "# df = pd.read_csv('https://raw.githubusercontent.com/davidbjourno/finding-stories-in-data/master/data/leave-demographics.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "See how easy that was? Now let's check that `df` is in fact a dataframe. Using the `.head(n=[number])` method on any dataframe will return the first `[number]` rows in that dataframe. Let's take a look at the first ten:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df.head(n=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks good!\n",
    "\n",
    "By now, you may have noticed that some of the row headers in this CSV aren't particularly descriptive (`var1`, `var2` etc.). This is the game: over the course of this tutorial, you're going to identify the variables that correlate most strongly with the percentage of â€˜leaveâ€™ votes (the `leave` column), i.e. which factors were the most predictive of people voting â€˜leaveâ€™. At the end of the meetup, before we all go down the pub, you can tell me which variables you think were the most predictive and I'll tell you what each of them are ðŸ˜"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Explore the data\n",
    "\n",
    "The main advantage of the workflow we're using here is that it enables us to inspect a dataset visually, which can often be the quickest way to identify patterns or trends in data. A common first step in this process is to use scatter plots to visualise the relationship between two variables, if any. So let's use Matplotlib to create a first, super basic [scatter plot](http://matplotlib.org/api/pyplot_api.html#matplotlib.pyplot.scatter):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Configure Matplotlib's pyplot method to plot at a size of 8x8 inches at a\n",
    "# resolution of 72 dots per inch\n",
    "plt.figure(figsize=(8, 8), dpi=72) \n",
    "\n",
    "# Plot the data as a scatter plot\n",
    "g = plt.scatter(\n",
    "    df['var1'], # The values we want to plot along the x axis\n",
    "    df['leave'], # The values we want to plot along the y axis\n",
    "    50, # The sizeâ€¦\n",
    "    '#0571b0', # â€¦colourâ€¦\n",
    "    alpha=0.5 # â€¦and opacity we want the data point markers to be\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Yikes, not much of a relationship there. Let's try a different variable:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 8), dpi=72)\n",
    "\n",
    "g = plt.scatter(\n",
    "    df['var2'], # Plotting var2_pc along the x axis this time\n",
    "    df['leave'],\n",
    "    50,\n",
    "    '#0571b0',\n",
    "    alpha=0.5\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hmm, the distribution looks betterâ€”there's a stronger (negative) correlation hereâ€”but it's still a little unclear what we're looking at. Let's add some context.\n",
    "\n",
    "We know from our provisional data-munging (that we didn't do) that many of the boroughs of London were among the strongest â€˜remainâ€™ areas in the country. We can add an additional field called `is_london` to our dataframe and set the values of that field to either `True` or `False` depending on whether the row's `region_name` field is equal to `'London'`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df['is_london'] = np.where(df['region_name'] == 'London', True, False)\n",
    "\n",
    "# Print all the rows in the dataframe in which the is_london field is equal to\n",
    "# True\n",
    "df[df['is_london'] == True]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Those names should look familiar. That's numpy's [`.where`](https://docs.scipy.org/doc/numpy/reference/generated/numpy.where.html) method coming in handy there to help us generate a new column of data based on the values of another columnâ€”in this case, `region_name`.\n",
    "\n",
    "At this point, we're going to abandon Matplotlib like merciless narcissists and turn our attention to the younger, hotter [Seaborn](https://seaborn.pydata.org/). Though it sounds like one of the factions from _Game of Thrones_, it's actually another plotting module that includes some handy analytical shortcuts and statistical methods. One of those analytical shortcuts is the [`FacetGrid`](http://seaborn.pydata.org/generated/seaborn.FacetGrid.html).\n",
    "\n",
    "If you've ever used [OpenRefine](http://openrefine.org/), you're probably familiar with the concept of faceting. I'll fumblingly describe it here as a method whereby data is apportioned into distinct matrices according to the values of a single field. You get the idea. Right now, we're going to facet on the `is_london` column so that we can distinguish the London boroughs from the rest of the UK:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Set the chart background colour (completely unnecessary, I just don't like the\n",
    "# default)\n",
    "sns.set_style('darkgrid', { 'axes.facecolor': '#efefef' })\n",
    "\n",
    "# Tell Seaborn that what we want from it is a FacetGrid, and assign this to the\n",
    "# variable â€˜fgâ€™\n",
    "fg = sns.FacetGrid(\n",
    "    df, # Use our dataframe as the input data\n",
    "    hue='is_london', # Highlight the data points for which is_london == True\n",
    "    palette=['#0571b0', '#ca0020'], # Define a tasteful blue/red colour combo\n",
    "    size=7 # Make the plots size 7, whatever that means\n",
    ")\n",
    "\n",
    "# Tell Seaborn that what we want to do with our FacetGrid (fg) is visualise it\n",
    "# as a scatter plot\n",
    "fg.map(\n",
    "    plt.scatter,\n",
    "    'var2', # Values to plot along the x axis\n",
    "    'leave', # Values to plot along the y axis\n",
    "    alpha=0.5 # Data point marker opacity\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we're cooking with gas! We can see a slight negative correlation in the distribution of the data points _and_ we can see how London compares to all the other regions of the country. Whatever `var2` is, we now know that the London boroughs generally have higher values in this field than most of the rest of the UK.\n",
    "\n",
    "So what's to stop you faceting on `is_london` but with a different variable plotted along the x axis? The answer is: nothing! Try doing that exact thing right now:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Plot the chart above with a different variable along the x axis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What's more, faceting isn't limited to just highlighting specific data points. We can also pass `FacetGrid` a `col` (column) argument with the name of a column that we'd like to use to further segment our data. So let's create another `True`/`False` ([Boolean](https://en.wikipedia.org/wiki/Boolean_data_type)) column to flag the areas with the largest populationsâ€”the ones with electorates of 100,000 people or moreâ€”and plot a new facet grid:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df['is_largest'] = np.where(df['electorate'] >= 100000, True, False)\n",
    "\n",
    "g = sns.FacetGrid(\n",
    "    df,\n",
    "    hue='is_london', \n",
    "    col='is_largest',\n",
    "    palette=['#0571b0', '#ca0020'],\n",
    "    size=7\n",
    ")\n",
    "\n",
    "g.map(\n",
    "    plt.scatter,\n",
    "    'var2',\n",
    "    'leave',\n",
    "    alpha=0.62\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we're able to make the following statements based solely on a visual inspection of this facet grid:\n",
    "\n",
    "* Most of the less populous areas (electorate < 100,000) voted â€˜leaveâ€™\n",
    "* Most of the less populous areas had `var2` values lower than 35. Only two â€“Â both London boroughs â€“ had values higher than 35\n",
    "* There is a stronger correlation between the strength of the â€˜leaveâ€™ vote and the value of `var2` among the more populous areas\n",
    "\n",
    "So you see how faceting can come in handy when you come to a dataset cold and need to start to understand it quickly.\n",
    "\n",
    "As yet, we still don't have much of a story, just a few observationsâ€”not exactly Pulitzer material. The next and most important step is to narrow down which of the variables in the dataset had the strongest influence on the likelihood of a â€˜leaveâ€™ vote. The good news is that we don't have to repeat the facet grid steps above for every variable, because Seaborn provides another useful analytical shortcut called a [`PairGrid`](https://seaborn.pydata.org/generated/seaborn.PairGrid.html#seaborn.PairGrid)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Optimise for efficiency\n",
    "\n",
    "Apparently there's an equivalent to the pair grid in R called a correlogram or something (I wouldn't know). But the pair grid is super sweet because it allows us to check for correlations among a number of variables at once. By passing the `PairGrid` function an array of specific variables in our dataset, we can plot each of those variables against every other variable in one amazing ultra-grid:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Just adding the first four variables, plus leave, to start withâ€”you'll see why\n",
    "grid_columns = [\n",
    "    'var1',\n",
    "    'var2',\n",
    "    'var3',\n",
    "    'var4',\n",
    "    'leave'\n",
    "]\n",
    "\n",
    "g = sns.PairGrid(\n",
    "    df[grid_columns],\n",
    "    palette='#0571b0'\n",
    ")\n",
    "\n",
    "g.map_offdiag(plt.scatter);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the pair grid, you should be able to identify which of the variables in the data set correlate most strongly with percentage of leave votes and whether the correlations are positive or negative.\n",
    "\n",
    "## 3. Make a viz and get it out of the notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "output_notebook()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Instantiate our plot\n",
    "p = bokeh.figure(\n",
    "    plot_width=600,\n",
    "    plot_height=422,\n",
    "    background_fill_color='#d3d3d3',\n",
    "    title='Leave demographics'\n",
    ")\n",
    "\n",
    "# Add a circle renderer to the plot\n",
    "p.circle(\n",
    "    df['var5'], # Values to plot along the x axis\n",
    "    df['leave'], # Values to plot along the y axis\n",
    "    # Size the markers according to the size of the electorate (scaled down)\n",
    "    size=df['electorate'] / 20000,\n",
    "    color='#ca0020',\n",
    "    line_width=1,\n",
    "    line_color='#ca0020',\n",
    "    alpha=0.5\n",
    ")\n",
    "\n",
    "# Configure the plot's x axis\n",
    "p.xaxis.axis_label = 'var5'\n",
    "p.xgrid.grid_line_color = None\n",
    "\n",
    "# Configure the plot's y axis\n",
    "p.yaxis.axis_label = 'Percentage voting leave'\n",
    "p.ygrid.grid_line_color = '#999999'\n",
    "p.ygrid.grid_line_alpha = 1\n",
    "p.ygrid.grid_line_dash = [6, 4]\n",
    "\n",
    "# Show the plot\n",
    "bokeh.show(p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Now that's starting to look like something we could publish. Refer to the [Bokeh docs](http://bokeh.pydata.org/en/latest/docs/user_guide.html) for more customisation options, and when you're happy with how your plot looks, click the â€˜Saveâ€™ button on the toolbar at the right of the plot to export it as a PNG image. If you want, you can even paste it into the [hackpad](https://journocoders.hackpad.com/Journocoders-April-2017-BLRJmLthZLk) with your nameâ€”coolest-looking one wins a drink!\n",
    "\n",
    "## 4. Baller-level challenges\n",
    "* Using pandas, identify the top ten â€˜leaveâ€™-voting areas in the country, both by vote percentage and per capita of the electorate\n",
    "* Recreate your Bokeh visualisation in D3 (in the notebook). [Hint](https://github.com/PyGoogle/PyD3)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
